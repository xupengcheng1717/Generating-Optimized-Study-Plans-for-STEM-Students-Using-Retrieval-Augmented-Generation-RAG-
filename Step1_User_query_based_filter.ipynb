{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.nn import CosineSimilarity\n",
    "import pandas as pd\n",
    "from keybert import KeyBERT\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is to conduct user query based filtering. Meaning given a user query, we will go through three filtering process.\n",
    "\n",
    "1. Perform similarity check for course info and wiki article title using FAISS (course info and wiki articles embedding with SentenceTransformer)\n",
    "2. Use trained two tower model to filter wiki articles based on user query + course info (course info was summarized to keywords using KWbert, then merged with user query to doing embedding using two tower model)\n",
    "3. Use pre-trained rerank model RankGPT to do re-ranking and pick the most important articles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Introduction to Business Analytics</td>\n",
       "      <td>This course provides students with an introduc...</td>\n",
       "      <td>Computer Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business Analytics Immersion Programme</td>\n",
       "      <td>This course aims to equip students with a firs...</td>\n",
       "      <td>Computer Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Econometrics Modeling for Business Analytics</td>\n",
       "      <td>This course provides the foundations to econom...</td>\n",
       "      <td>Computer Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Management and Visualisation</td>\n",
       "      <td>This course aims to provide students with prac...</td>\n",
       "      <td>Computer Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Feature Engineering for Machine Learning</td>\n",
       "      <td>This course covers topics that are important f...</td>\n",
       "      <td>Computer Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>Introduction to Hyperledger Sovereign Identity...</td>\n",
       "      <td>To the surprise of absolutely no one, trust is...</td>\n",
       "      <td>Computer Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>A System View of Communications: From Signals ...</td>\n",
       "      <td>Have you ever wondered how information is tran...</td>\n",
       "      <td>Computer Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>Scripting and Programming Foundations</td>\n",
       "      <td>Computer programs are abundant in many people'...</td>\n",
       "      <td>Computer Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>Using GPUs to Scale and Speed-up Deep Learning</td>\n",
       "      <td>Training acomplex deep learning model with a v...</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>The Power of Data</td>\n",
       "      <td>Key course outcomesHigh level overview of the ...</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1916 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title  \\\n",
       "0                    Introduction to Business Analytics   \n",
       "1                Business Analytics Immersion Programme   \n",
       "2          Econometrics Modeling for Business Analytics   \n",
       "3                     Data Management and Visualisation   \n",
       "4              Feature Engineering for Machine Learning   \n",
       "...                                                 ...   \n",
       "1911  Introduction to Hyperledger Sovereign Identity...   \n",
       "1912  A System View of Communications: From Signals ...   \n",
       "1913              Scripting and Programming Foundations   \n",
       "1914     Using GPUs to Scale and Speed-up Deep Learning   \n",
       "1915                                  The Power of Data   \n",
       "\n",
       "                                            Description           Subject  \n",
       "0     This course provides students with an introduc...  Computer Science  \n",
       "1     This course aims to equip students with a firs...  Computer Science  \n",
       "2     This course provides the foundations to econom...  Computer Science  \n",
       "3     This course aims to provide students with prac...  Computer Science  \n",
       "4     This course covers topics that are important f...  Computer Science  \n",
       "...                                                 ...               ...  \n",
       "1911  To the surprise of absolutely no one, trust is...  Computer Science  \n",
       "1912  Have you ever wondered how information is tran...  Computer Science  \n",
       "1913  Computer programs are abundant in many people'...  Computer Science  \n",
       "1914  Training acomplex deep learning model with a v...      Data Science  \n",
       "1915  Key course outcomesHigh level overview of the ...      Data Science  \n",
       "\n",
       "[1916 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'Combined_course_data.csv'\n",
    "course = pd.read_csv(file_path)\n",
    "course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Becurtovirus is a genus of viruses, in the fam...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Becurtovirus</td>\n",
       "      <td>Becurtovirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cyprinivirus is a genus of viruses in the orde...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cyprinivirus</td>\n",
       "      <td>Cyprinivirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glossinavirus is a genus of viruses, in the fa...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Glossinavirus</td>\n",
       "      <td>Glossinavirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ichtadenovirus is a genus of viruses, in the f...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Ichtadenovirus</td>\n",
       "      <td>Ichtadenovirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lambdatorquevirus is a genus of viruses, in th...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Lambdatorquevirus</td>\n",
       "      <td>Lambdatorquevirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131044</th>\n",
       "      <td>A non-blanching rash (NBR) is a skin rash that...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Non-blanching%20...</td>\n",
       "      <td>Non-blanching rash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131045</th>\n",
       "      <td>In organic chemistry, the term cyanomethyl (cy...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cyanomethyl</td>\n",
       "      <td>Cyanomethyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131046</th>\n",
       "      <td>Remaiten is malware which infects Linux on emb...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Remaiten</td>\n",
       "      <td>Remaiten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131047</th>\n",
       "      <td>Gradient-enhanced kriging (GEK) is a surrogate...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Gradient-enhance...</td>\n",
       "      <td>Gradient-enhanced kriging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131048</th>\n",
       "      <td>Cry6Aa (Pesticidal crystal protein Cry6Aa) is ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cry6Aa</td>\n",
       "      <td>Cry6Aa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131049 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "0       Becurtovirus is a genus of viruses, in the fam...   \n",
       "1       Cyprinivirus is a genus of viruses in the orde...   \n",
       "2       Glossinavirus is a genus of viruses, in the fa...   \n",
       "3       Ichtadenovirus is a genus of viruses, in the f...   \n",
       "4       Lambdatorquevirus is a genus of viruses, in th...   \n",
       "...                                                   ...   \n",
       "131044  A non-blanching rash (NBR) is a skin rash that...   \n",
       "131045  In organic chemistry, the term cyanomethyl (cy...   \n",
       "131046  Remaiten is malware which infects Linux on emb...   \n",
       "131047  Gradient-enhanced kriging (GEK) is a surrogate...   \n",
       "131048  Cry6Aa (Pesticidal crystal protein Cry6Aa) is ...   \n",
       "\n",
       "                                                      url  \\\n",
       "0              https://en.wikipedia.org/wiki/Becurtovirus   \n",
       "1              https://en.wikipedia.org/wiki/Cyprinivirus   \n",
       "2             https://en.wikipedia.org/wiki/Glossinavirus   \n",
       "3            https://en.wikipedia.org/wiki/Ichtadenovirus   \n",
       "4         https://en.wikipedia.org/wiki/Lambdatorquevirus   \n",
       "...                                                   ...   \n",
       "131044  https://en.wikipedia.org/wiki/Non-blanching%20...   \n",
       "131045          https://en.wikipedia.org/wiki/Cyanomethyl   \n",
       "131046             https://en.wikipedia.org/wiki/Remaiten   \n",
       "131047  https://en.wikipedia.org/wiki/Gradient-enhance...   \n",
       "131048               https://en.wikipedia.org/wiki/Cry6Aa   \n",
       "\n",
       "                            title  \n",
       "0                    Becurtovirus  \n",
       "1                    Cyprinivirus  \n",
       "2                   Glossinavirus  \n",
       "3                  Ichtadenovirus  \n",
       "4               Lambdatorquevirus  \n",
       "...                           ...  \n",
       "131044         Non-blanching rash  \n",
       "131045                Cyanomethyl  \n",
       "131046                   Remaiten  \n",
       "131047  Gradient-enhanced kriging  \n",
       "131048                     Cry6Aa  \n",
       "\n",
       "[131049 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'wikidata.csv'\n",
    "wikidata = pd.read_csv(file_path)\n",
    "wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Course Data:\n",
      "                                             content\n",
      "0  Title: Introduction to Business Analytics | De...\n",
      "1  Title: Business Analytics Immersion Programme ...\n",
      "2  Title: Econometrics Modeling for Business Anal...\n",
      "3  Title: Data Management and Visualisation | Des...\n",
      "4  Title: Feature Engineering for Machine Learnin...\n",
      "\n",
      "Transformed Wikidata:\n",
      "                                             content\n",
      "0  text: Becurtovirus is a genus of viruses, in t...\n",
      "1  text: Cyprinivirus is a genus of viruses in th...\n",
      "2  text: Glossinavirus is a genus of viruses, in ...\n",
      "3  text: Ichtadenovirus is a genus of viruses, in...\n",
      "4  text: Lambdatorquevirus is a genus of viruses,...\n"
     ]
    }
   ],
   "source": [
    "course_transformed = pd.DataFrame({\n",
    "    \"content\": course.apply(lambda row: ' | '.join([f\"{col}: {row[col]}\" for col in course.columns]), axis=1)\n",
    "})\n",
    "\n",
    "# Transform `wikidata` DataFrame to a single-column format\n",
    "wikidata_transformed = pd.DataFrame({\n",
    "    \"content\": wikidata.apply(lambda row: ' | '.join([f\"{col}: {row[col]}\" for col in wikidata.columns]), axis=1)\n",
    "})\n",
    "\n",
    "# Display the transformed tables\n",
    "print(\"Transformed Course Data:\")\n",
    "print(course_transformed.head())\n",
    "\n",
    "print(\"\\nTransformed Wikidata:\")\n",
    "print(wikidata_transformed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load wiki_title_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01740786,  0.00442912, -0.09215238, ..., -0.02191604,\n",
       "         0.07291625, -0.02235293],\n",
       "       [-0.10091388,  0.0783674 , -0.04533364, ..., -0.1075331 ,\n",
       "         0.04686709,  0.07207245],\n",
       "       [-0.10018466, -0.00640676, -0.0114509 , ..., -0.14957273,\n",
       "         0.06115797,  0.02614287],\n",
       "       ...,\n",
       "       [-0.03868212,  0.05411112,  0.00084907, ...,  0.01953804,\n",
       "        -0.01381   , -0.04266216],\n",
       "       [-0.09186076, -0.1078757 ,  0.04518463, ..., -0.042975  ,\n",
       "        -0.03663828,  0.01403402],\n",
       "       [-0.06280275,  0.0021886 , -0.00058878, ..., -0.0114022 ,\n",
       "        -0.0395432 , -0.0105731 ]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_embeddings_file = 'wiki_title_embeddings.npy'\n",
    "wiki_title_embeddings = np.load(wiki_embeddings_file)\n",
    "wiki_title_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Perform similarity check for course info and wiki article title using FAISS (13k -> 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Title: Data-Driven Marketing | Description: In today’s environment, marketing or business analysts require tools and techniques to both quantify the strategic value of marketing initiatives, and to maximize marketing campaign performance. This course aims to teach students concepts, methods and tools to demonstrate the return on investment (ROI) of marketing activities and to leverage on data and marketing analytics to make better and more informed marketing decisions. Course topics covered include marketing performance management, marketing metrics, data management, market response and diffusion models, market and customer segmentation models, analytic marketing and value driven segmentation, digital media marketing analytics, etc. Students will have access to | Subject: Computer Science'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "course_info = course_transformed['content'][17]\n",
    "course_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "course_embedding = model.encode(course_info)\n",
    "\n",
    "# Step 3: Use FAISS to retrieve top 500 relevant Wikipedia titles based on the course embedding\n",
    "dimension = wiki_title_embeddings.shape[1]\n",
    "faiss_index = faiss.IndexFlatL2(dimension)\n",
    "faiss_index.add(wiki_title_embeddings)\n",
    "\n",
    "# Retrieve the top 50 most relevant Wikipedia titles\n",
    "num_candidates = 500\n",
    "_, top_k_indices = faiss_index.search(np.array([course_embedding]), num_candidates)\n",
    "\n",
    "# Filter the top 30 Wikipedia entries\n",
    "top_500_wikidata = pd.DataFrame()\n",
    "top_500_wikidata = wikidata_transformed.iloc[top_k_indices[0]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text: User behavior analytics (UBA) is a cyber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text: Data mining, the process of discovering ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text: A rally is a period of sustained increas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text: The AIDA model is just one of a class of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text: The category development index (CDI) mea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>text: Demand priority is a media-access method...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>text: In systems science, a  sampled-data syst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>text: For bees, their forage or food supply co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>text: Information quality (InfoQ) is the poten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>text: In computer networking, the User Datagra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content\n",
       "0    text: User behavior analytics (UBA) is a cyber...\n",
       "1    text: Data mining, the process of discovering ...\n",
       "2    text: A rally is a period of sustained increas...\n",
       "3    text: The AIDA model is just one of a class of...\n",
       "4    text: The category development index (CDI) mea...\n",
       "..                                                 ...\n",
       "495  text: Demand priority is a media-access method...\n",
       "496  text: In systems science, a  sampled-data syst...\n",
       "497  text: For bees, their forage or food supply co...\n",
       "498  text: Information quality (InfoQ) is the poten...\n",
       "499  text: In computer networking, the User Datagra...\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_500_wikidata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Use trained two tower model to filter wiki articles based on user query + course info (500 -> 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keybert import KeyBERT\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.nn import CosineSimilarity\n",
    "\n",
    "# Initialize models and tokenizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "query_model = AutoModel.from_pretrained(\"query_model_scidocs\").to(device)\n",
    "document_model = AutoModel.from_pretrained(\"document_model_scidocs\").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tokenizer_scidocs\")\n",
    "cosine_sim = CosineSimilarity(dim=1)\n",
    "kw_model = KeyBERT()\n",
    "\n",
    "# Define your utility functions\n",
    "def encode_text(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=64).to(device)\n",
    "    embeddings = model(**inputs).last_hidden_state[:, 0, :]  # CLS token embedding\n",
    "    return embeddings\n",
    "\n",
    "def extract_keywords(content, model):\n",
    "    keywords = model.extract_keywords(content, keyphrase_ngram_range=(3, 3), stop_words='english',\n",
    "                                      use_maxsum=True, nr_candidates=20, top_n=5)\n",
    "    merged_keywords = \" \".join([kw[0] for kw in keywords])\n",
    "    return merged_keywords\n",
    "\n",
    "def calculate_similarity(query_text, document_text):\n",
    "    query_embedding = encode_text(query_text, tokenizer, query_model)\n",
    "    document_embedding = encode_text(document_text, tokenizer, document_model)\n",
    "    similarity_score = cosine_sim(query_embedding, document_embedding).item()\n",
    "    return similarity_score\n",
    "\n",
    "def refine_user_query_1(query, kw):\n",
    "    return query + \"which has following keywords:\" + kw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock user's query\n",
    "user_query = \"Can you help me make a study plan for the course: Data-Driven Marketing?\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can you help me make a study plan for the course: Data-Driven Marketing?which has following keywords:marketing description today investment roi marketing marketing analytics make marketing decisions course leverage data marketing'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_keywords = extract_keywords(course_info, kw_model)\n",
    "user_query = refine_user_query_1(user_query, merged_keywords)\n",
    "user_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_50_candidates = []\n",
    "\n",
    "\n",
    "\n",
    "query_embedding = encode_text(user_query, tokenizer, query_model)\n",
    "\n",
    "\n",
    "for _, row in top_500_wikidata.iterrows():\n",
    "    # Step 2: Extract keywords from the document content\n",
    "    \n",
    "    \n",
    "    # Step 3: Embed the merged keywords using the document model\n",
    "    doc_embedding = encode_text(row['content'], tokenizer, document_model)\n",
    "    \n",
    "    # Step 4: Calculate similarity score between the course embedding and document embedding\n",
    "    similarity_score = cosine_sim(query_embedding, doc_embedding).item()\n",
    "    \n",
    "    # Store title, keywords, and similarity score\n",
    "    top_50_candidates.append({\n",
    "        \"Content\": row['content'],\n",
    "        #\"Keywords\": merged_keywords,\n",
    "        \"Similarity Score\": similarity_score\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Similarity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text: User behavior analytics (UBA) is a cyber...</td>\n",
       "      <td>0.989267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>text: To classify postoperative outcomes for e...</td>\n",
       "      <td>0.988383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>text: Software installed in medical devices is...</td>\n",
       "      <td>0.988083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>text: Unsupervised learning  is a type of algo...</td>\n",
       "      <td>0.987775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>text: This is a list of mathematics-based meth...</td>\n",
       "      <td>0.987758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>text: Usage data is the most effective way of ...</td>\n",
       "      <td>0.987555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>text: Learning pathway is described as the cho...</td>\n",
       "      <td>0.987185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>text: Macrotasking is a type of crowdsourcing ...</td>\n",
       "      <td>0.987081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>text: Utilising the DW/BI system is the final ...</td>\n",
       "      <td>0.987036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>text: Data portability is a concept to protect...</td>\n",
       "      <td>0.986632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>text: Associative browsing is the professional...</td>\n",
       "      <td>0.986603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>text: This page provides supplementary chemica...</td>\n",
       "      <td>0.986549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>text: MSCRAMM (acronym for \"microbial surface ...</td>\n",
       "      <td>0.986522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>text: Information-centric networking (ICN) is ...</td>\n",
       "      <td>0.986460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>text: A deductive database is a database syste...</td>\n",
       "      <td>0.986371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>text: Automatic Device Model Synthesizer (ADMS...</td>\n",
       "      <td>0.986342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>text: An asset in economic theory is a durable...</td>\n",
       "      <td>0.986270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>text: Process Decision Program Chart (PDPC) is...</td>\n",
       "      <td>0.986044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>text: Proactive learning is a generalization o...</td>\n",
       "      <td>0.985829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>text: BriX is a database containing some prote...</td>\n",
       "      <td>0.985714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>text: In network science, the activity-driven ...</td>\n",
       "      <td>0.985513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>text: KPI driven code analysis (KPI = Key Perf...</td>\n",
       "      <td>0.985495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>text: In the field of programming a data trans...</td>\n",
       "      <td>0.985480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>text: Multimedia Class Scheduler Service (MMCS...</td>\n",
       "      <td>0.985442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>text: Program-specific information (PSI) is me...</td>\n",
       "      <td>0.985421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>text: Stochastic frontier analysis (SFA) is a ...</td>\n",
       "      <td>0.985394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>text: Data loss prevention (DLP) software dete...</td>\n",
       "      <td>0.985372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>text: A relational data stream management syst...</td>\n",
       "      <td>0.985324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>text: The Short Message Service is realised by...</td>\n",
       "      <td>0.985255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>text: 1С:Enterprise is a development platform ...</td>\n",
       "      <td>0.985240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>text: Informetrics is the study of quantitativ...</td>\n",
       "      <td>0.985236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>text: The Market Facilitation Index  (MFI) is ...</td>\n",
       "      <td>0.985068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>text: Clinomics is the study of -omics data al...</td>\n",
       "      <td>0.985041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>text: The Biopharmaceutics Classification Syst...</td>\n",
       "      <td>0.985038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>text: Data exhaust or exhaust data is the trai...</td>\n",
       "      <td>0.985023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>text: Magisk is an Android application primari...</td>\n",
       "      <td>0.985016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>text: Macrocognition indicates a descriptive l...</td>\n",
       "      <td>0.984986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>text: In network science, a hub is a node with...</td>\n",
       "      <td>0.984979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>text: Data wrangling, sometimes referred to as...</td>\n",
       "      <td>0.984975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>text: Microtechnique is an aggregate of method...</td>\n",
       "      <td>0.984968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>text: Data retrieval means obtaining data from...</td>\n",
       "      <td>0.984814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>text: The EmDrive is a concept for a thruster ...</td>\n",
       "      <td>0.984808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>text: Cost-effectiveness analysis (CEA) is a f...</td>\n",
       "      <td>0.984798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>text: Data feed is a mechanism for users to re...</td>\n",
       "      <td>0.984796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>text: In financial markets, a pivot point is a...</td>\n",
       "      <td>0.984791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>text: Asset tracking refers to the method of t...</td>\n",
       "      <td>0.984677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>text: Netdata is an open source tool designed ...</td>\n",
       "      <td>0.984572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>text: In machine learning, boosting is an ense...</td>\n",
       "      <td>0.984504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>text: Global R&amp;D management is the discipline ...</td>\n",
       "      <td>0.984461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>text: This a list of statistical procedures wh...</td>\n",
       "      <td>0.984429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Content  Similarity Score\n",
       "0    text: User behavior analytics (UBA) is a cyber...          0.989267\n",
       "268  text: To classify postoperative outcomes for e...          0.988383\n",
       "421  text: Software installed in medical devices is...          0.988083\n",
       "364  text: Unsupervised learning  is a type of algo...          0.987775\n",
       "342  text: This is a list of mathematics-based meth...          0.987758\n",
       "8    text: Usage data is the most effective way of ...          0.987555\n",
       "34   text: Learning pathway is described as the cho...          0.987185\n",
       "318  text: Macrotasking is a type of crowdsourcing ...          0.987081\n",
       "21   text: Utilising the DW/BI system is the final ...          0.987036\n",
       "370  text: Data portability is a concept to protect...          0.986632\n",
       "392  text: Associative browsing is the professional...          0.986603\n",
       "368  text: This page provides supplementary chemica...          0.986549\n",
       "320  text: MSCRAMM (acronym for \"microbial surface ...          0.986522\n",
       "461  text: Information-centric networking (ICN) is ...          0.986460\n",
       "378  text: A deductive database is a database syste...          0.986371\n",
       "217  text: Automatic Device Model Synthesizer (ADMS...          0.986342\n",
       "127  text: An asset in economic theory is a durable...          0.986270\n",
       "147  text: Process Decision Program Chart (PDPC) is...          0.986044\n",
       "192  text: Proactive learning is a generalization o...          0.985829\n",
       "405  text: BriX is a database containing some prote...          0.985714\n",
       "41   text: In network science, the activity-driven ...          0.985513\n",
       "304  text: KPI driven code analysis (KPI = Key Perf...          0.985495\n",
       "297  text: In the field of programming a data trans...          0.985480\n",
       "258  text: Multimedia Class Scheduler Service (MMCS...          0.985442\n",
       "227  text: Program-specific information (PSI) is me...          0.985421\n",
       "480  text: Stochastic frontier analysis (SFA) is a ...          0.985394\n",
       "174  text: Data loss prevention (DLP) software dete...          0.985372\n",
       "347  text: A relational data stream management syst...          0.985324\n",
       "170  text: The Short Message Service is realised by...          0.985255\n",
       "232  text: 1С:Enterprise is a development platform ...          0.985240\n",
       "118  text: Informetrics is the study of quantitativ...          0.985236\n",
       "56   text: The Market Facilitation Index  (MFI) is ...          0.985068\n",
       "443  text: Clinomics is the study of -omics data al...          0.985041\n",
       "196  text: The Biopharmaceutics Classification Syst...          0.985038\n",
       "59   text: Data exhaust or exhaust data is the trai...          0.985023\n",
       "219  text: Magisk is an Android application primari...          0.985016\n",
       "339  text: Macrocognition indicates a descriptive l...          0.984986\n",
       "290  text: In network science, a hub is a node with...          0.984979\n",
       "30   text: Data wrangling, sometimes referred to as...          0.984975\n",
       "257  text: Microtechnique is an aggregate of method...          0.984968\n",
       "121  text: Data retrieval means obtaining data from...          0.984814\n",
       "462  text: The EmDrive is a concept for a thruster ...          0.984808\n",
       "132  text: Cost-effectiveness analysis (CEA) is a f...          0.984798\n",
       "6    text: Data feed is a mechanism for users to re...          0.984796\n",
       "19   text: In financial markets, a pivot point is a...          0.984791\n",
       "310  text: Asset tracking refers to the method of t...          0.984677\n",
       "394  text: Netdata is an open source tool designed ...          0.984572\n",
       "208  text: In machine learning, boosting is an ense...          0.984504\n",
       "145  text: Global R&D management is the discipline ...          0.984461\n",
       "45   text: This a list of statistical procedures wh...          0.984429"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_50_df = pd.DataFrame(top_50_candidates).sort_values(by=\"Similarity Score\", ascending=False).head(50)\n",
    "top_50_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 3. Use pre-trained rerank model RankGPT to do re-ranking and pick the most important articles (50 -> 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text: User behavior analytics (UBA) is a cybersecurity process about detection of insider threats, targeted attacks, and financial fraud that tracks a system\\'s users. UBA looks at patterns of human behavior, and then analyzes them to detect anomalies that indicate potential threats. Big data platforms like Apache Hadoop are increasing UBA functionality by allowing them to analyze petabytes worth of data to detect insider threats and advanced persistent threats.\\n\\nPurpose \\nUBA\\'s purpose, according to Johna Till Johnson of Nemertes Research, is that \"Security systems provide so much information that it\\'s tough to uncover information that truly indicates a potential for real attack. Analytics tools help make sense of the vast amount of data that SIEM, IDS/IPS, system logs, and other tools gather. UBA tools use a specialized type of security analytics that focuses on the behavior of systems and the people using them. UBA technology first evolved in the field of marketing, to help companies understand and predict consumer-buying patterns. But as it turns out, UBA can be extraordinarily useful in the security context too.\"\\n\\nSee also\\n Behavioral analytics\\n Network behavior anomaly detection\\n\\nReferences\\n\\nExternal links\\n\\nABC\\'s Of UBA\\n\\nSoftware | url: https://en.wikipedia.org/wiki/User%20behavior%20analytics | title: User behavior analytics',\n",
       " 'text: Software installed in medical devices is assessed for health and safety issues according to international standards.\\n\\nSafety classes \\nSoftware classification is based on the potential for hazard(s) that could cause injury to the user or patient.\\n\\nPer [[IEC 62304|IEC 62304:2006] + A1:2015], the software can be divided into three separate classes:\\n The SOFTWARE SYSTEM is software safety class A if:\\nthe SOFTWARE SYSTEM cannot contribute to a HAZARDOUS SITUATION; or\\nthe SOFTWARE SYSTEM can contribute to a HAZARDOUS SITUATION which does not result in unacceptable RISK after consideration of RISK CONTROL measures external to the SOFTWARE SYSTEM.\\nThe SOFTWARE SYSTEM is software safety class B if:\\nthe SOFTWARE SYSTEM can contribute to a HAZARDOUS SITUATION which results in unacceptable RISK after consideration of RISK CONTROL measures external to the SOFTWARE SYSTEM and the resulting possible HARM is non-SERIOUS INJURY.\\nThe SOFTWARE SYSTEM is software safety class C if:\\nthe SOFTWARE SYSTEM can contribute to a HAZARDOUS SITUATION which results in unacceptable RISK after consideration of RISK CONTROL measures external to the SOFTWARE SYSTEM and the resulting possible HARM is death or SERIOUS INJURY“\\n\\nSerious injury \\nFor the purpose of this classification, serious injury is defined as injury or illness that directly or indirectly is life threatening; results in permanent impairment of a body function or permanent damage to a body structure; or necessitates medical or surgical intervention to prevent permanent impairment of a body function or permanent damage to a body structure.\\n\\nReferences\\n\\nSoftware\\nOccupational safety and health | url: https://en.wikipedia.org/wiki/Software%20safety%20classification | title: Software safety classification',\n",
       " 'text: Unsupervised learning  is a type of algorithm that learns patterns from untagged data. The hope is that through mimicry, which is an important mode of learning in people, the machine is forced to build a compact internal representation of its world and then generate imaginative content from it. In contrast to supervised learning where data is tagged by an expert, e.g. as a \"ball\" or \"fish\", unsupervised methods exhibit self-organization that captures patterns as probability densities  or a combination of neural feature preferences. The other levels in the supervision spectrum are reinforcement learning where the machine is given only a numerical performance score as guidance, and semi-supervised learning where a smaller portion of the data is tagged. Two broad methods in Unsupervised Learning are Neural Networks and Probabilistic Methods.\\n\\nNeural networks\\n\\nTasks vs. Methods \\n\\nNeural network tasks are often categorized as discriminative (recognition) or generative (imagination).  Often but not always, discriminative tasks use supervised methods and generative tasks use unsupervised (see Venn diagram); however, the separation is very hazy.  For example, object recognition favors supervised learning but unsupervised learning can also cluster objects into groups.  Furthermore, as progress marches onward some tasks employ both methods, and some tasks swing from one to another.  For example, image recognition started off as heavily supervised, but became hybrid by employing unsupervised pre-training, and then moved towards supervision again with the advent of dropout, relu, and adaptive learning rates.\\n\\nTraining \\nDuring the learning phase, an unsupervised network tries to mimic the data it\\'s given and uses the error in its mimicked output to correct itself (ie. correct its weights & biases). This resembles the mimicry behavior of children as they learn a language.  Sometimes the error is expressed as a low probability that the erroneous output occurs, or it might be express as an unstable high energy state in the network.\\n\\nIn contrast to Supervised method\\'s dominant use of Backpropagation, Unsupervised Learning also employ other methods  including:  Hopfield learning rule, Boltzmann learning rule, Contrastive Divergence, Wake Sleep, Variational Inference, Maximum Likelihood, Maximum A Posteriori, Gibbs Sampling, and backpropagating reconstruction errors or hidden state reparameterizations.  See the table below for more details.\\n\\nEnergy \\nAn energy function is a macroscopic measure of a network\\'s activation state.  In Boltzmann machines, it plays the role of the Cost function.  This analogy with physics is inspired by Ludwig Boltzmann\\'s analysis of a gas\\' macroscopic energy from the microscopic probabilities of particle motion p  eE/kT, where k is the Boltzmann constant and T is temperature. In the RBM network the relation is p = e−E / Z, where p & E vary over every possible activation pattern and Z =  e -E(pattern). To be more precise, p(a) = e-E(a) / Z, where a is an activation pattern of all neurons (visible and hidden). Hence, early neural networks bear the name Boltzmann Machine.  Paul Smolensky calls -E the Harmony. A network seeks low energy which is high Harmony.\\n\\nNetworks \\nThis table shows connection diagrams of various unsupervised networks, the details of which will be given in the section Comparison of Network.  Of the networks bearing people\\'s names, only Hopfield worked directly with neural networks.  Boltzmann and Helmholtz lived before the invention of artificial neural networks, but they did inspire the analytical methods that were used.\\n\\nHistory\\n\\nSpecific Networks \\n\\nHere, we highlight some characteristics of each networks. Ferromagnetism inspired Hopfield networks, Boltzmann machines, and RBMs. A neuron correspond to an iron domain with binary magnetic moments Up and Down, and neural connections correspond to the domain\\'s influence on each other. Symmetric connections enables a global energy formulation. During inference the network updates each state using the standard activation step function. Symmetric weights guarantees convergence to a stable activation pattern.\\n\\nComparison of Networks \\n\\nHebbian Learning, ART, SOM\\nThe classical example of unsupervised learning in the study of neural networks is Donald Hebb\\'s principle, that is, neurons that fire together wire together. In Hebbian learning, the connection is reinforced irrespective of an error, but is exclusively a function of the coincidence between action potentials between the two neurons. A similar version that modifies synaptic weights takes into account the time between the action potentials (spike-timing-dependent plasticity or STDP). Hebbian Learning has been hypothesized to underlie a range of cognitive functions, such as pattern recognition and experiential learning.\\n\\nAmong neural network models, the self-organizing map (SOM) and adaptive resonance theory (ART) are commonly used in unsupervised learning algorithms. The SOM is a topographic organization in which nearby locations in the map represent inputs with similar properties. The ART model allows the number of clusters to vary with problem size and lets the user control the degree of similarity between members of the same clusters by means of a user-defined constant called the vigilance parameter. ART networks are used for many pattern recognition tasks, such as automatic target recognition and seismic signal processing.\\n\\nProbabilistic methods \\nTwo of the main methods used in unsupervised learning are principal component and cluster analysis. Cluster analysis is used in unsupervised learning to group, or segment, datasets with shared attributes in order to extrapolate algorithmic relationships. Cluster analysis is a branch of machine learning that groups the data that has not been labelled, classified or categorized. Instead of responding to feedback, cluster analysis identifies commonalities in the data and reacts based on the presence or absence of such commonalities in each new piece of data. This approach helps detect anomalous data points that do not fit into either group.\\n\\nA central application of unsupervised learning is in the field of density estimation in statistics, though unsupervised learning encompasses many other domains involving summarizing and explaining data features. It can be contrasted with supervised learning by saying that whereas supervised learning intends to infer a conditional probability distribution  conditioned on the label  of input data; unsupervised learning intends to infer an a priori probability distribution .\\n\\nApproaches \\nSome of the most common algorithms used in unsupervised learning include: (1) Clustering, (2) Anomaly detection, (3) Approaches for learning latent variable models. Each approach uses several methods as follows:\\n\\n Clustering methods include: hierarchical clustering, k-means, mixture models, DBSCAN, and OPTICS algorithm\\n Anomaly detection methods include: Local Outlier Factor, and Isolation Forest\\n Approaches for learning latent variable models such as Expectation–maximization algorithm (EM), Method of moments, and Blind signal separation techniques (Principal component analysis, Independent component analysis, Non-negative matrix factorization, Singular value decomposition)\\n\\nMethod of moments \\nOne of the statistical approaches for unsupervised learning is the method of moments. In the method of moments, the unknown parameters (of interest) in the model are related to the moments of one or more random variables, and thus, these unknown parameters can be estimated given the moments. The moments are usually estimated from samples empirically. The basic moments are first and second order moments. For a random vector, the first order moment is the mean vector, and the second order moment is the covariance matrix (when the mean is zero). Higher order moments are usually represented using tensors which are the generalization of matrices to higher orders as multi-dimensional arrays.\\n\\nIn particular, the method of moments is shown to be effective in learning the parameters of latent variable models. Latent variable models are statistical models where in addition to the observed variables, a set of latent variables also exists which is not observed. A highly practical example of latent variable models in machine learning is the topic modeling which is a statistical model for generating the words (observed variables) in the document based on the topic (latent variable) of the document. In the topic modeling, the words in the document are generated according to different statistical parameters when the topic of the document is changed. It is shown that method of moments (tensor decomposition techniques) consistently recover the parameters of a large class of latent variable models under some assumptions.\\n\\nThe Expectation–maximization algorithm (EM) is also one of the most practical methods for learning latent variable models. However, it can get stuck in local optima, and it is not guaranteed that the algorithm will converge to the true unknown parameters of the model. In contrast, for the method of moments, the global convergence is guaranteed under some conditions.\\n\\nSee also \\n Automated machine learning\\n Cluster analysis\\n Anomaly detection\\n Expectation–maximization algorithm\\n Generative topographic map\\n Meta-learning (computer science)\\n Multivariate analysis\\n Radial basis function network\\nWeak supervision\\n\\nReferences\\n\\nFurther reading \\n \\n \\n\\n  (This book focuses on unsupervised learning in neural networks)\\n\\n \\nMachine learning | url: https://en.wikipedia.org/wiki/Unsupervised%20learning | title: Unsupervised learning',\n",
       " 'text: To classify postoperative outcomes for epilepsy surgery, Jerome Engel proposed the following scheme, the Engel Epilepsy Surgery Outcome Scale, which has become the de facto standard when reporting results in the medical literature:\\n Class I: Free of disabling seizures\\n Class II: Rare disabling seizures (\"almost seizure-free\")\\n Class III: Worthwhile improvement\\n Class IV: No worthwhile improvement\\n\\nHistory\\n\\nSurgery for epilepsy patients has been used for over a century, but due to technological restrictions and insufficient knowledge of brain surgery, this treatment approach was relatively rare until the 1980s and 90s.  Prior to the 1980s, no classification system existed due to the lack of operations performed up until the time. As surgery as a treatment grew more prevalent, a classification system became a necessity. The appropriate evaluation of patients following epilepsy surgery is extremely important, as medical professionals must know the appropriate course of action to follow in order to achieve seizure freedom for patients.  Accordingly, the Engel classification guidelines were devised by UCLA neurologist Jerome Engel Jr. in 1987 and made public at the 1992 Palm Desert Conference on Epilepsy Surgery. The Engel classification system has since become the standard in reporting postoperative outcomes of epilepsy surgery.\\n\\nOverview\\n\\nIn Engel\\'s 1993 summary of the 1992 Palm Desert Conference on Epilepsy Surgery, he annotated his classification system with more detail.  The annotation was as follows:\\n Class I: Seizure free or no more than a few early, nondisabling seizures; or seizures upon drug withdrawal only\\n Class II: Disabling seizures occur rarely during a period of at least 2 years; disabling seizures may have been more frequent soon after surgery; nocturnal seizures\\n Class III: Worthwhile improvement; seizure reduction for prolonged periods but less than 2 years\\n Class IV: No worthwhile improvement; some reduction, no reduction, or worsening are possible\\n\\nAdvantages\\n\\nThe subjectivity of the Engel system leaves much of the postoperative class assignment process to the patients. While many have noted the disadvantages of a classification system where the patients are involved in determining the evaluation, others have praised it.  Proponents of the Engel classification guidelines argue that the patients are best able to perceive the worth of the operation because they are the ones experiencing the seizures before and after the treatment.\\n\\nDisadvantages\\n\\nAs is the case for all current methods of reviewing epilepsy surgery outcomes, the Engel classification system has subjective components. A \"disabling seizure\" is subjective and can vary in definition from person to person. While one epileptic experiencing a seizure when driving a car may find the seizure \"disabling,\" the same magnitude of seizure may be interpreted as mild, and thus \"nondisabling,\" by an epileptic resting in bed. Every class other than class I is also subjective because there is no quantitative definition of what determines a rare occurrence or method to measure worthwhileness. One doctor and patient may consider 2 seizures in a year as a rare occurrence while another doctor may consider 10 in a year as rarely occurring. The worthwhileness of the operation is ambiguous because worth can be interpreted differently by various patients and healthcare professionals. Keeping those caveats in mind, most neurologists and neurosurgeons who specialize in epilepsy would most likely agree, as would many epileptics and even laypeople, that any seizure that leads to a period of status epilepticus (seizure activity, especially of the tonic-clonic, or grand mal, type, for longer than about five to ten minutes, or more- some now say it should be as little as two- without an intervening return to normal, or any repeat seizures without a return to consciousness) is a medical emergency, objectively a major problem, and cannot be considered a satisfactory outcome (unless perhaps if the person had a fatal or very severe form of a neurodegenerative syndrome or other disease where such severe repeat seizures are not unusual, and there are a number of these diseases; even then, such an outcome is usually still not a cure, just an amelioration of a fatal condition or a very disabling condition). Continuing to have to endure a large number of tonic-clonic seizures (grand mal seizures) over a period of days, months, or even over the course of a year or two, would make it impossible to drive and very hard to hold a job away from home entailing much stress, and would pose limits on one\\'s abilities to safely carry out the activities of daily living without at least some monitoring or assistance.\\n\\nThe Engel classification system has been thought of as a cross-sectional grading system by medical professionals because it does not account for long term changes in patients.  It has been proposed that it would be more beneficial to reevaluate patients on an annual basis, and the International League Against Epilepsy (ILAE) devised a separate rating scale in 2001 that reevaluates patients on every annual anniversary of their surgery. The ILAE also developed their system in hopes of avoiding many of the subjective components found in the Engel system.\\n\\nReferences\\n\\nMedical terminology\\nNeurological disorders\\nNeurology\\nEpilepsy | url: https://en.wikipedia.org/wiki/Engel%20classification | title: Engel classification',\n",
       " \"text: This is a list of mathematics-based methods.\\n\\nAdams' method (differential equations)\\nAkra–Bazzi method (asymptotic analysis)\\nBisection method (root finding)\\nBrent's method (root finding)\\nCondorcet method (voting systems)\\nCoombs' method (voting systems)\\nCopeland's method (voting systems)\\nCrank–Nicolson method (numerical analysis)\\nD'Hondt method (voting systems)\\nD21 – Janeček method (voting system)\\nDiscrete element method (numerical analysis)\\nDomain decomposition method (numerical analysis)\\nEpidemiological methods\\nEuler's forward method\\nExplicit and implicit methods (numerical analysis)\\nFinite difference method (numerical analysis)\\nFinite element method (numerical analysis)\\nFinite volume method (numerical analysis)\\nHighest averages method (voting systems)\\nMethod of exhaustion\\nMethod of infinite descent (number theory)\\nInformation bottleneck method\\nInverse chain rule method (calculus)\\nInverse transform sampling method (probability)\\nIterative method (numerical analysis)\\nJacobi method (linear algebra)\\nLargest remainder method (voting systems)\\nLevel-set method\\nLinear combination of atomic orbitals molecular orbital method (molecular orbitals)\\nMethod of characteristics\\nLeast squares method (optimization, statistics)\\nMaximum likelihood method (statistics)\\nMethod of complements (arithmetic)\\nMethod of moving frames (differential geometry)\\nMethod of successive substitution (number theory)\\nMonte Carlo method (computational physics, simulation)\\nNewton's method (numerical analysis)\\nPemdas method (order of operation)\\nPerturbation methods (functional analysis, quantum theory)\\nProbabilistic method (combinatorics)\\nRomberg's method (numerical analysis)\\nRunge–Kutta method (numerical analysis)\\nSainte-Laguë method (voting systems)\\nSchulze method (voting systems)\\nSequential Monte Carlo method\\nSimplex method\\nSpectral method (numerical analysis)\\nVariational methods (mathematical analysis, differential equations)\\nWelch's method\\n\\nSee also\\n Automatic basis function construction\\n List of graphical methods\\n Scientific method\\n\\nMethods\\nScientific method | url: https://en.wikipedia.org/wiki/List%20of%20mathematics-based%20methods | title: List of mathematics-based methods\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "from rank_gpt import permutation_pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Set up your OpenAI API key\n",
    "openai.api_key = \"\"\n",
    "\n",
    "\n",
    "# Convert top_5_df into the required format for `permutation_pipeline`\n",
    "item = {\n",
    "    \"query\": user_query,\n",
    "    \"hits\": [{\"content\": content} for content in top_50_df[\"Content\"]]  # Assuming `top_5_df` has a \"Content\" column\n",
    "}\n",
    "\n",
    "# Use `permutation_pipeline` to re-rank the top 5 articles and get the reordered list\n",
    "new_item = permutation_pipeline(item, rank_start=0, rank_end=5, model_name='gpt-3.5-turbo', api_key=openai.api_key)\n",
    "\n",
    "# Extract the top 3 articles from the re-ranked output\n",
    "top_5_articles = [hit[\"content\"] for hit in new_item[\"hits\"][:5]]\n",
    "\n",
    "top_5_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course Overview:\n",
      "Title: Data-Driven Marketing | Description: In today’s environment, marketing or business analysts require tools and techniques to both quantify the strategic value of marketing initiatives, and to maximize marketing campaign performance. This course aims to teach students concepts, methods and tools to demonstrate the return on investment (ROI) of marketing activities and to leverage on data and marketing analytics to make better and more informed marketing decisions. Course topics covered include marketing performance management, marketing metrics, data management, market response and diffusion models, market and customer segmentation models, analytic marketing and value driven segmentation, digital media marketing analytics, etc. Students will have access to | Subject: Computer Science\n",
      "\n",
      "Related Article 1:\n",
      "Title: Article 1\n",
      "Content: text: User behavior analytics (UBA) is a cybersecurity process about detection of insider threats, targeted attacks, and financial fraud that tracks a system's users. UBA looks at patterns of human behavior, and then analyzes them to detect anomalies that indicate potential threats. Big data platforms like Apache Hadoop are increasing UBA functionality by allowing them to analyze petabytes worth of data to detect insider threats and advanced persistent threats.\n",
      "\n",
      "Purpose \n",
      "UBA's purpose, according to Johna Till Johnson of Nemertes Research, is that \"Security systems provide so much information that it's tough to uncover information that truly indicates a potential for real attack. Analytics tools help make sense of the vast amount of data that SIEM, IDS/IPS, system logs, and other tools gather. UBA tools use a specialized type of security analytics that focuses on the behavior of systems and the people using them. UBA technology first evolved in the field of marketing, to help companies understand and predict consumer-buying patterns. But as it turns out, UBA can be extraordinarily useful in the security context too.\"\n",
      "\n",
      "See also\n",
      " Behavioral analytics\n",
      " Network behavior anomaly detection\n",
      "\n",
      "References\n",
      "\n",
      "External links\n",
      "\n",
      "ABC's Of UBA\n",
      "\n",
      "Software | url: https://en.wikipedia.org/wiki/User%20behavior%20analytics | title: User behavior analytics\n",
      "\n",
      "\n",
      "In addition, the following article provides insights:\n",
      "\n",
      "Related Article 2:\n",
      "Title: Article 2\n",
      "Content: text: Software installed in medical devices is assessed for health and safety issues according to international standards.\n",
      "\n",
      "Safety classes \n",
      "Software classification is based on the potential for hazard(s) that could cause injury to the user or patient.\n",
      "\n",
      "Per [[IEC 62304|IEC 62304:2006] + A1:2015], the software can be divided into three separate classes:\n",
      " The SOFTWARE SYSTEM is software safety class A if:\n",
      "the SOFTWARE SYSTEM cannot contribute to a HAZARDOUS SITUATION; or\n",
      "the SOFTWARE SYSTEM can contribute to a HAZARDOUS SITUATION which does not result in unacceptable RISK after consideration of RISK CONTROL measures external to the SOFTWARE SYSTEM.\n",
      "The SOFTWARE SYSTEM is software safety class B if:\n",
      "the SOFTWARE SYSTEM can contribute to a HAZARDOUS SITUATION which results in unacceptable RISK after consideration of RISK CONTROL measures external to the SOFTWARE SYSTEM and the resulting possible HARM is non-SERIOUS INJURY.\n",
      "The SOFTWARE SYSTEM is software safety class C if:\n",
      "the SOFTWARE SYSTEM can contribute to a HAZARDOUS SITUATION which results in unacceptable RISK after consideration of RISK CONTROL measures external to the SOFTWARE SYSTEM and the resulting possible HARM is death or SERIOUS INJURY“\n",
      "\n",
      "Serious injury \n",
      "For the purpose of this classification, serious injury is defined as injury or illness that directly or indirectly is life threatening; results in permanent impairment of a body function or permanent damage to a body structure; or necessitates medical or surgical intervention to prevent permanent impairment of a body function or permanent damage to a body structure.\n",
      "\n",
      "References\n",
      "\n",
      "Software\n",
      "Occupational safety and health | url: https://en.wikipedia.org/wiki/Software%20safety%20classification | title: Software safety classification\n",
      "\n",
      "\n",
      "In addition, the following article provides insights:\n",
      "\n",
      "Related Article 3:\n",
      "Title: Article 3\n",
      "Content: text: To classify postoperative outcomes for epilepsy surgery, Jerome Engel proposed the following scheme, the Engel Epilepsy Surgery Outcome Scale, which has become the de facto standard when reporting results in the medical literature:\n",
      " Class I: Free of disabling seizures\n",
      " Class II: Rare disabling seizures (\"almost seizure-free\")\n",
      " Class III: Worthwhile improvement\n",
      " Class IV: No worthwhile improvement\n",
      "\n",
      "History\n",
      "\n",
      "Surgery for epilepsy patients has been used for over a century, but due to technological restrictions and insufficient knowledge of brain surgery, this treatment approach was relatively rare until the 1980s and 90s.  Prior to the 1980s, no classification system existed due to the lack of operations performed up until the time. As surgery as a treatment grew more prevalent, a classification system became a necessity. The appropriate evaluation of patients following epilepsy surgery is extremely important, as medical professionals must know the appropriate course of action to follow in order to achieve seizure freedom for patients.  Accordingly, the Engel classification guidelines were devised by UCLA neurologist Jerome Engel Jr. in 1987 and made public at the 1992 Palm Desert Conference on Epilepsy Surgery. The Engel classification system has since become the standard in reporting postoperative outcomes of epilepsy surgery.\n",
      "\n",
      "Overview\n",
      "\n",
      "In Engel's 1993 summary of the 1992 Palm Desert Conference on Epilepsy Surgery, he annotated his classification system with more detail.  The annotation was as follows:\n",
      " Class I: Seizure free or no more than a few early, nondisabling seizures; or seizures upon drug withdrawal only\n",
      " Class II: Disabling seizures occur rarely during a period of at least 2 years; disabling seizures may have been more frequent soon after surgery; nocturnal seizures\n",
      " Class III: Worthwhile improvement; seizure reduction for prolonged periods but less than 2 years\n",
      " Class IV: No worthwhile improvement; some reduction, no reduction, or worsening are possible\n",
      "\n",
      "Advantages\n",
      "\n",
      "The subjectivity of the Engel system leaves much of the postoperative class assignment process to the patients. While many have noted the disadvantages of a classification system where the patients are involved in determining the evaluation, others have praised it.  Proponents of the Engel classification guidelines argue that the patients are best able to perceive the worth of the operation because they are the ones experiencing the seizures before and after the treatment.\n",
      "\n",
      "Disadvantages\n",
      "\n",
      "As is the case for all current methods of reviewing epilepsy surgery outcomes, the Engel classification system has subjective components. A \"disabling seizure\" is subjective and can vary in definition from person to person. While one epileptic experiencing a seizure when driving a car may find the seizure \"disabling,\" the same magnitude of seizure may be interpreted as mild, and thus \"nondisabling,\" by an epileptic resting in bed. Every class other than class I is also subjective because there is no quantitative definition of what determines a rare occurrence or method to measure worthwhileness. One doctor and patient may consider 2 seizures in a year as a rare occurrence while another doctor may consider 10 in a year as rarely occurring. The worthwhileness of the operation is ambiguous because worth can be interpreted differently by various patients and healthcare professionals. Keeping those caveats in mind, most neurologists and neurosurgeons who specialize in epilepsy would most likely agree, as would many epileptics and even laypeople, that any seizure that leads to a period of status epilepticus (seizure activity, especially of the tonic-clonic, or grand mal, type, for longer than about five to ten minutes, or more- some now say it should be as little as two- without an intervening return to normal, or any repeat seizures without a return to consciousness) is a medical emergency, objectively a major problem, and cannot be considered a satisfactory outcome (unless perhaps if the person had a fatal or very severe form of a neurodegenerative syndrome or other disease where such severe repeat seizures are not unusual, and there are a number of these diseases; even then, such an outcome is usually still not a cure, just an amelioration of a fatal condition or a very disabling condition). Continuing to have to endure a large number of tonic-clonic seizures (grand mal seizures) over a period of days, months, or even over the course of a year or two, would make it impossible to drive and very hard to hold a job away from home entailing much stress, and would pose limits on one's abilities to safely carry out the activities of daily living without at least some monitoring or assistance.\n",
      "\n",
      "The Engel classification system has been thought of as a cross-sectional grading system by medical professionals because it does not account for long term changes in patients.  It has been proposed that it would be more beneficial to reevaluate patients on an annual basis, and the International League Against Epilepsy (ILAE) devised a separate rating scale in 2001 that reevaluates patients on every annual anniversary of their surgery. The ILAE also developed their system in hopes of avoiding many of the subjective components found in the Engel system.\n",
      "\n",
      "References\n",
      "\n",
      "Medical terminology\n",
      "Neurological disorders\n",
      "Neurology\n",
      "Epilepsy | url: https://en.wikipedia.org/wiki/Engel%20classification | title: Engel classification\n",
      "\n",
      "\n",
      "In addition, the following article provides insights:\n",
      "\n",
      "Related Article 4:\n",
      "Title: Article 4\n",
      "Content: text: Unsupervised learning  is a type of algorithm that learns patterns from untagged data. The hope is that through mimicry, which is an important mode of learning in people, the machine is forced to build a compact internal representation of its world and then generate imaginative content from it. In contrast to supervised learning where data is tagged by an expert, e.g. as a \"ball\" or \"fish\", unsupervised methods exhibit self-organization that captures patterns as probability densities  or a combination of neural feature preferences. The other levels in the supervision spectrum are reinforcement learning where the machine is given only a numerical performance score as guidance, and semi-supervised learning where a smaller portion of the data is tagged. Two broad methods in Unsupervised Learning are Neural Networks and Probabilistic Methods.\n",
      "\n",
      "Neural networks\n",
      "\n",
      "Tasks vs. Methods \n",
      "\n",
      "Neural network tasks are often categorized as discriminative (recognition) or generative (imagination).  Often but not always, discriminative tasks use supervised methods and generative tasks use unsupervised (see Venn diagram); however, the separation is very hazy.  For example, object recognition favors supervised learning but unsupervised learning can also cluster objects into groups.  Furthermore, as progress marches onward some tasks employ both methods, and some tasks swing from one to another.  For example, image recognition started off as heavily supervised, but became hybrid by employing unsupervised pre-training, and then moved towards supervision again with the advent of dropout, relu, and adaptive learning rates.\n",
      "\n",
      "Training \n",
      "During the learning phase, an unsupervised network tries to mimic the data it's given and uses the error in its mimicked output to correct itself (ie. correct its weights & biases). This resembles the mimicry behavior of children as they learn a language.  Sometimes the error is expressed as a low probability that the erroneous output occurs, or it might be express as an unstable high energy state in the network.\n",
      "\n",
      "In contrast to Supervised method's dominant use of Backpropagation, Unsupervised Learning also employ other methods  including:  Hopfield learning rule, Boltzmann learning rule, Contrastive Divergence, Wake Sleep, Variational Inference, Maximum Likelihood, Maximum A Posteriori, Gibbs Sampling, and backpropagating reconstruction errors or hidden state reparameterizations.  See the table below for more details.\n",
      "\n",
      "Energy \n",
      "An energy function is a macroscopic measure of a network's activation state.  In Boltzmann machines, it plays the role of the Cost function.  This analogy with physics is inspired by Ludwig Boltzmann's analysis of a gas' macroscopic energy from the microscopic probabilities of particle motion p  eE/kT, where k is the Boltzmann constant and T is temperature. In the RBM network the relation is p = e−E / Z, where p & E vary over every possible activation pattern and Z =  e -E(pattern). To be more precise, p(a) = e-E(a) / Z, where a is an activation pattern of all neurons (visible and hidden). Hence, early neural networks bear the name Boltzmann Machine.  Paul Smolensky calls -E the Harmony. A network seeks low energy which is high Harmony.\n",
      "\n",
      "Networks \n",
      "This table shows connection diagrams of various unsupervised networks, the details of which will be given in the section Comparison of Network.  Of the networks bearing people's names, only Hopfield worked directly with neural networks.  Boltzmann and Helmholtz lived before the invention of artificial neural networks, but they did inspire the analytical methods that were used.\n",
      "\n",
      "History\n",
      "\n",
      "Specific Networks \n",
      "\n",
      "Here, we highlight some characteristics of each networks. Ferromagnetism inspired Hopfield networks, Boltzmann machines, and RBMs. A neuron correspond to an iron domain with binary magnetic moments Up and Down, and neural connections correspond to the domain's influence on each other. Symmetric connections enables a global energy formulation. During inference the network updates each state using the standard activation step function. Symmetric weights guarantees convergence to a stable activation pattern.\n",
      "\n",
      "Comparison of Networks \n",
      "\n",
      "Hebbian Learning, ART, SOM\n",
      "The classical example of unsupervised learning in the study of neural networks is Donald Hebb's principle, that is, neurons that fire together wire together. In Hebbian learning, the connection is reinforced irrespective of an error, but is exclusively a function of the coincidence between action potentials between the two neurons. A similar version that modifies synaptic weights takes into account the time between the action potentials (spike-timing-dependent plasticity or STDP). Hebbian Learning has been hypothesized to underlie a range of cognitive functions, such as pattern recognition and experiential learning.\n",
      "\n",
      "Among neural network models, the self-organizing map (SOM) and adaptive resonance theory (ART) are commonly used in unsupervised learning algorithms. The SOM is a topographic organization in which nearby locations in the map represent inputs with similar properties. The ART model allows the number of clusters to vary with problem size and lets the user control the degree of similarity between members of the same clusters by means of a user-defined constant called the vigilance parameter. ART networks are used for many pattern recognition tasks, such as automatic target recognition and seismic signal processing.\n",
      "\n",
      "Probabilistic methods \n",
      "Two of the main methods used in unsupervised learning are principal component and cluster analysis. Cluster analysis is used in unsupervised learning to group, or segment, datasets with shared attributes in order to extrapolate algorithmic relationships. Cluster analysis is a branch of machine learning that groups the data that has not been labelled, classified or categorized. Instead of responding to feedback, cluster analysis identifies commonalities in the data and reacts based on the presence or absence of such commonalities in each new piece of data. This approach helps detect anomalous data points that do not fit into either group.\n",
      "\n",
      "A central application of unsupervised learning is in the field of density estimation in statistics, though unsupervised learning encompasses many other domains involving summarizing and explaining data features. It can be contrasted with supervised learning by saying that whereas supervised learning intends to infer a conditional probability distribution  conditioned on the label  of input data; unsupervised learning intends to infer an a priori probability distribution .\n",
      "\n",
      "Approaches \n",
      "Some of the most common algorithms used in unsupervised learning include: (1) Clustering, (2) Anomaly detection, (3) Approaches for learning latent variable models. Each approach uses several methods as follows:\n",
      "\n",
      " Clustering methods include: hierarchical clustering, k-means, mixture models, DBSCAN, and OPTICS algorithm\n",
      " Anomaly detection methods include: Local Outlier Factor, and Isolation Forest\n",
      " Approaches for learning latent variable models such as Expectation–maximization algorithm (EM), Method of moments, and Blind signal separation techniques (Principal component analysis, Independent component analysis, Non-negative matrix factorization, Singular value decomposition)\n",
      "\n",
      "Method of moments \n",
      "One of the statistical approaches for unsupervised learning is the method of moments. In the method of moments, the unknown parameters (of interest) in the model are related to the moments of one or more random variables, and thus, these unknown parameters can be estimated given the moments. The moments are usually estimated from samples empirically. The basic moments are first and second order moments. For a random vector, the first order moment is the mean vector, and the second order moment is the covariance matrix (when the mean is zero). Higher order moments are usually represented using tensors which are the generalization of matrices to higher orders as multi-dimensional arrays.\n",
      "\n",
      "In particular, the method of moments is shown to be effective in learning the parameters of latent variable models. Latent variable models are statistical models where in addition to the observed variables, a set of latent variables also exists which is not observed. A highly practical example of latent variable models in machine learning is the topic modeling which is a statistical model for generating the words (observed variables) in the document based on the topic (latent variable) of the document. In the topic modeling, the words in the document are generated according to different statistical parameters when the topic of the document is changed. It is shown that method of moments (tensor decomposition techniques) consistently recover the parameters of a large class of latent variable models under some assumptions.\n",
      "\n",
      "The Expectation–maximization algorithm (EM) is also one of the most practical methods for learning latent variable models. However, it can get stuck in local optima, and it is not guaranteed that the algorithm will converge to the true unknown parameters of the model. In contrast, for the method of moments, the global convergence is guaranteed under some conditions.\n",
      "\n",
      "See also \n",
      " Automated machine learning\n",
      " Cluster analysis\n",
      " Anomaly detection\n",
      " Expectation–maximization algorithm\n",
      " Generative topographic map\n",
      " Meta-learning (computer science)\n",
      " Multivariate analysis\n",
      " Radial basis function network\n",
      "Weak supervision\n",
      "\n",
      "References\n",
      "\n",
      "Further reading \n",
      " \n",
      " \n",
      "\n",
      "  (This book focuses on unsupervised learning in neural networks)\n",
      "\n",
      " \n",
      "Machine learning | url: https://en.wikipedia.org/wiki/Unsupervised%20learning | title: Unsupervised learning\n",
      "\n",
      "\n",
      "In addition, the following article provides insights:\n",
      "\n",
      "Related Article 5:\n",
      "Title: Article 5\n",
      "Content: text: This is a list of mathematics-based methods.\n",
      "\n",
      "Adams' method (differential equations)\n",
      "Akra–Bazzi method (asymptotic analysis)\n",
      "Bisection method (root finding)\n",
      "Brent's method (root finding)\n",
      "Condorcet method (voting systems)\n",
      "Coombs' method (voting systems)\n",
      "Copeland's method (voting systems)\n",
      "Crank–Nicolson method (numerical analysis)\n",
      "D'Hondt method (voting systems)\n",
      "D21 – Janeček method (voting system)\n",
      "Discrete element method (numerical analysis)\n",
      "Domain decomposition method (numerical analysis)\n",
      "Epidemiological methods\n",
      "Euler's forward method\n",
      "Explicit and implicit methods (numerical analysis)\n",
      "Finite difference method (numerical analysis)\n",
      "Finite element method (numerical analysis)\n",
      "Finite volume method (numerical analysis)\n",
      "Highest averages method (voting systems)\n",
      "Method of exhaustion\n",
      "Method of infinite descent (number theory)\n",
      "Information bottleneck method\n",
      "Inverse chain rule method (calculus)\n",
      "Inverse transform sampling method (probability)\n",
      "Iterative method (numerical analysis)\n",
      "Jacobi method (linear algebra)\n",
      "Largest remainder method (voting systems)\n",
      "Level-set method\n",
      "Linear combination of atomic orbitals molecular orbital method (molecular orbitals)\n",
      "Method of characteristics\n",
      "Least squares method (optimization, statistics)\n",
      "Maximum likelihood method (statistics)\n",
      "Method of complements (arithmetic)\n",
      "Method of moving frames (differential geometry)\n",
      "Method of successive substitution (number theory)\n",
      "Monte Carlo method (computational physics, simulation)\n",
      "Newton's method (numerical analysis)\n",
      "Pemdas method (order of operation)\n",
      "Perturbation methods (functional analysis, quantum theory)\n",
      "Probabilistic method (combinatorics)\n",
      "Romberg's method (numerical analysis)\n",
      "Runge–Kutta method (numerical analysis)\n",
      "Sainte-Laguë method (voting systems)\n",
      "Schulze method (voting systems)\n",
      "Sequential Monte Carlo method\n",
      "Simplex method\n",
      "Spectral method (numerical analysis)\n",
      "Variational methods (mathematical analysis, differential equations)\n",
      "Welch's method\n",
      "\n",
      "See also\n",
      " Automatic basis function construction\n",
      " List of graphical methods\n",
      " Scientific method\n",
      "\n",
      "Methods\n",
      "Scientific method | url: https://en.wikipedia.org/wiki/List%20of%20mathematics-based%20methods | title: List of mathematics-based methods\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def construct_document(course_info, top_articles):\n",
    "    # Template to create a more readable and coherent document structure\n",
    "    document = f\"Course Overview:\\n{course_info}\\n\\n\"\n",
    "    for i, article in enumerate(top_articles, 1):\n",
    "        document += f\"Related Article {i}:\\n\"\n",
    "        document += f\"Title: Article {i}\\n\"\n",
    "        document += f\"Content: {article}\\n\"\n",
    "        if i < len(top_articles):\n",
    "            document += \"\\n\\nIn addition, the following article provides insights:\\n\\n\"\n",
    "    return document\n",
    "\n",
    "final_document = construct_document(course_info, top_5_articles)\n",
    "print(final_document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document saved as final_document.txt\n"
     ]
    }
   ],
   "source": [
    "def save_text_to_file(text, filename=\"final_document.txt\"):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text)\n",
    "    print(f\"Document saved as {filename}\")\n",
    "\n",
    "# Example usage\n",
    "save_text_to_file(final_document)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
